{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import nemo.collections.asr as nemo_asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CSV = './1_stage_preprocessed_data.csv'\n",
    "AUDIO_FILES_DIR = '/media/real/data/uzbekvoice/clips'\n",
    "OUTPUT_CSV = './2_stage_preprocessed_data.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model  this model is trained on not cleaned dataset \n",
    "quartznet_saved= nemo_asr.models.EncDecCTCModel.restore_from(\"./saved_model/quartznet15x5.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_result(audio_filepath):\n",
    "    # check if file exists \n",
    "    if not os.path.isfile(audio_filepath):\n",
    "        return None    \n",
    "    return quartznet_saved.transcribe(paths2audio_files=[audio_filepath])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    \"\"\"Calculate the Levenshtein distance between two strings.\"\"\"\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for index2, char2 in enumerate(s2):\n",
    "        new_distances = [index2 + 1]\n",
    "        for index1, char1 in enumerate(s1):\n",
    "            if char1 == char2:\n",
    "                new_distances.append(distances[index1])\n",
    "            else:\n",
    "                new_distances.append(1 + min((distances[index1], distances[index1 + 1], new_distances[-1])))\n",
    "        distances = new_distances\n",
    "\n",
    "    return distances[-1]\n",
    "\n",
    "def calculate_error_rates(real_transcription, model_transcription):\n",
    "    # Calculate Character Error Rate (CER)\n",
    "    cer = levenshtein_distance(real_transcription, model_transcription) / len(real_transcription)\n",
    "\n",
    "    # Calculate Sentence Error Rate (SER)\n",
    "    ser = 0 if real_transcription == model_transcription else 1\n",
    "\n",
    "    return cer, ser\n",
    "\n",
    "# Example usage:\n",
    "real_transcription = \"hello borld\"\n",
    "model_transcription = \"hello world\"\n",
    "cer, ser = calculate_error_rates(real_transcription, model_transcription)\n",
    "print(f\"Character Error Rate (CER): {cer:.2f}\")\n",
    "print(f\"Sentence Error Rate (SER): {ser:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 1 stage preprocessed data\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_file_path is a f\"/media/real/data/uzbekvoice/clips/{entry['client_id']}/{entry['original_sentence_id']}.wav\"\n",
    "\n",
    "df['audio_file_path'] = df.apply(lambda row: os.path.join(AUDIO_FILES_DIR, row['client_id'], f\"{row['original_sentence_id']}.wav\"), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# do inference on all audio files and save inference results to new column and calculate error rates \n",
    "df['inference_result'] = df['audio_file_path'].apply(get_inference_result)\n",
    "\n",
    "df['cer'] = df.apply(lambda row: calculate_error_rates(row['transcription'], row['inference_result'])[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df.to_csv(OUTPUT_CSV, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeMo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
